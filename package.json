{
  "name": "@mako10k/mcp-llm-generator",
  "version": "1.0.0",
  "description": "ðŸš€ Production-ready MCP server with advanced LLM text generation, context memory, and intelligent template systems. Features 67% token reduction optimization, personality-driven consultants, and associative memory for enhanced AI workflows.",
  "type": "module",
  "main": "build/index.js",
  "types": "build/index.d.ts",
  "bin": {
    "mcp-llm-generator": "build/index.js"
  },
  "files": [
    "build/",
    "templates/templates.json.sample",
    "README.md",
    "LICENSE"
  ],
  "sideEffects": false,
  "publishConfig": {
    "access": "public"
  },
  "scripts": {
    "build": "tsc",
    "start": "node build/index.js",
    "dev": "tsx src/index.ts",
    "prepare": "husky",
    "test": "echo \"Error: no test specified\" && exit 1"
  },
  "keywords": [
    "mcp",
    "model-context-protocol",
    "llm",
    "text-generation",
    "templates",
    "typescript",
    "ai",
    "claude",
    "anthropic",
    "cli",
    "generator"
  ],
  "engines": {
    "node": ">=18"
  },
  "repository": {
    "type": "git",
    "url": "https://github.com/mako10k/mcp-llm-generator.git"
  },
  "homepage": "https://github.com/mako10k/mcp-llm-generator#readme",
  "bugs": {
    "url": "https://github.com/mako10k/mcp-llm-generator/issues"
  },
  "license": "MIT",
  "author": {
    "name": "mako10k",
    "url": "https://github.com/mako10k"
  },
  "funding": {
    "type": "github",
    "url": "https://github.com/sponsors/mako10k"
  },
  "dependencies": {
    "@modelcontextprotocol/sdk": "^1.2.0",
    "@types/better-sqlite3": "^7.6.13",
    "better-sqlite3": "^12.2.0",
    "zod": "^3.22.4"
  },
  "devDependencies": {
    "@types/node": "^20.0.0",
    "husky": "^9.1.7",
    "tsx": "^4.7.0",
    "typescript": "^5.3.0"
  }
}
